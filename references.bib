@Preamble{ " \newcommand{\noop}[1]{} " }

@misc{gibbs2021adaptive,
  title={Adaptive Conformal Inference Under Distribution Shift}, 
  author={Isaac Gibbs and Emmanuel Candès},
  year={2021},
  eprint={2106.00170},
  archivePrefix={arXiv},
  primaryClass={stat.ME}
}


@InProceedings{zaffran2022agaci,
  title =    {Adaptive Conformal Predictions for Time Series},
  author =       {Zaffran, Margaux and Feron, Olivier and Goude, Yannig and Josse, Julie and Dieuleveut, Aymeric},
  booktitle =    {Proceedings of the 39th International Conference on Machine Learning},
  pages =    {25834--25866},
  year =   {2022},
  editor =   {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume =   {162},
  series =   {Proceedings of Machine Learning Research},
  month =    {17--23 Jul},
  publisher =    {PMLR},
  pdf =    {https://proceedings.mlr.press/v162/zaffran22a/zaffran22a.pdf},
  url =    {https://proceedings.mlr.press/v162/zaffran22a.html},
  abstract =   {Uncertainty quantification of predictive models is crucial in decision-making problems. Conformal prediction is a general and theoretically sound answer. However, it requires exchangeable data, excluding time series. While recent works tackled this issue, we argue that Adaptive Conformal Inference (ACI, Gibbs &amp; Cand{è}s, 2021), developed for distribution-shift time series, is a good procedure for time series with general dependency. We theoretically analyse the impact of the learning rate on its efficiency in the exchangeable and auto-regressive case. We propose a parameter-free method, AgACI, that adaptively builds upon ACI based on online expert aggregation. We lead extensive fair simulations against competing methods that advocate for ACI’s use in time series. We conduct a real case study: electricity price forecasting. The proposed aggregation algorithm provides efficient prediction intervals for day-ahead forecasting. All the code and data to reproduce the experiments are made available on GitHub.}
}

@misc{gibbs2022faci,
  title={Conformal Inference for Online Prediction with Arbitrary Distribution Shifts}, 
  author={Isaac Gibbs and Emmanuel Candès},
  year={2022},
  eprint={2208.08401},
  archivePrefix={arXiv},
  primaryClass={stat.ME}
}

@misc{bhatnagar2023saocp,
  title={Improved Online Conformal Prediction via Strongly Adaptive Online Learning}, 
  author={Aadyot Bhatnagar and Huan Wang and Caiming Xiong and Yu Bai},
  year={2023},
  eprint={2302.07869},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@misc{angelopoulos2022gentle,
      title={A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification}, 
      author={Anastasios N. Angelopoulos and Stephen Bates},
      year={2022},
      eprint={2107.07511},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{barber2023conformal,
      title={Conformal prediction beyond exchangeability}, 
      author={Rina Foygel Barber and Emmanuel J. Candes and Aaditya Ramdas and Ryan J. Tibshirani},
      year={2023},
      eprint={2202.13415},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@misc{jung2022batch,
      title={Batch Multivalid Conformal Prediction}, 
      author={Christopher Jung and Georgy Noarov and Ramya Ramalingam and Aaron Roth},
      year={2022},
      eprint={2209.15145},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{bastani2022practical,
      title={Practical Adversarial Multivalid Conformal Prediction}, 
      author={Osbert Bastani and Varun Gupta and Christopher Jung and Georgy Noarov and Ramya Ramalingam and Aaron Roth},
      year={2022},
      eprint={2206.01067},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{vovk2005,
  author = {Vovk, Vladimir and Gammerman, Alex and Shafer, Glenn},
  title = {Algorithmic Learning in a Random World},
  year = {2005},
  isbn = {0387001522},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg}
}

@Manual{opera2023,
    title = {opera: Online Prediction by Expert Aggregation},
    author = {Pierre Gaillard and Yannig Goude and Laurent Plagne and Thibaut Dubois and Benoit Thieurmel},
    year = {2023},
    note = {R package version 1.2.1},
    url = {http://pierre.gaillard.me/opera.html},
  }

@Article{wintenberger2017boa,
  author={Wintenberger, Olivier},
  title={Optimal learning with Bernstein online aggregation},
  journal={Machine Learning},
  year={2017},
  month={Jan},
  day={01},
  volume={106},
  number={1},
  pages={119-141},
  abstract={We introduce a new recursive aggregation procedure called Bernstein Online Aggregation (BOA). Its exponential weights include a second order refinement. The procedure is optimal for the model selection aggregation problem in the bounded iid setting for the square loss: the excess of risk of its batch version achieves the fast rate of convergence {\$}{\$}{\backslash}log (M)/n{\$}{\$}in deviation. The BOA procedure is the first online algorithm that satisfies this optimal fast rate. The second order refinement is required to achieve the optimality in deviation as the classical exponential weights cannot be optimal, see Audibert (Advances in neural information processing systems. MIT Press, Cambridge, MA, 2007). This refinement is settled thanks to a new stochastic conversion that estimates the cumulative predictive risk in any stochastic environment with observable second order terms. The observable second order term is shown to be sufficiently small to assert the fast rate in the iid setting when the loss is Lipschitz and strongly convex. We also introduce a multiple learning rates version of BOA. This fully adaptive BOA procedure is also optimal, up to a {\$}{\$}{\backslash}log {\backslash}log (n){\$}{\$}factor.},
  issn={1573-0565},
  doi={10.1007/s10994-016-5592-6},
  url={https://doi.org/10.1007/s10994-016-5592-6}
}

@article{orabona2018sfogd,
  title = {Scale-free online learning},
  journal = {Theoretical Computer Science},
  volume = {716},
  pages = {50-69},
  year = {2018},
  note = {Special Issue on ALT 2015},
  issn = {0304-3975},
  doi = {https://doi.org/10.1016/j.tcs.2017.11.021},
  url = {https://www.sciencedirect.com/science/article/pii/S0304397517308514},
  author = {Francesco Orabona and Dávid Pál},
  keywords = {Online algorithms, Optimization, Regret bounds, Online learning},
  abstract = {We design and analyze algorithms for online linear optimization that have optimal regret and at the same time do not need to know any upper or lower bounds on the norm of the loss vectors. Our algorithms are instances of the Follow the Regularized Leader (FTRL) and Mirror Descent (MD) meta-algorithms. We achieve adaptiveness to the norms of the loss vectors by scale invariance, i.e., our algorithms make exactly the same decisions if the sequence of loss vectors is multiplied by any positive constant. The algorithm based on FTRL works for any decision set, bounded or unbounded. For unbounded decisions sets, this is the first adaptive algorithm for online linear optimization with a non-vacuous regret bound. In contrast, we show lower bounds on scale-free algorithms based on MD on unbounded domains.}
}

@misc{gradu2022adaptive,
      title={Adaptive Regret for Control of Time-Varying Dynamics}, 
      author={Paula Gradu and Elad Hazan and Edgar Minasyan},
      year={2022},
      eprint={2007.04393},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gradu2022adaptive,
      title={Adaptive Regret for Control of Time-Varying Dynamics}, 
      author={Paula Gradu and Elad Hazan and Edgar Minasyan},
      year={2022},
      eprint={2007.04393},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{cesabianchi2006games,
  place={Cambridge}, 
  title={Prediction, Learning, and Games},
  DOI={10.1017/CBO9780511546921}, 
  publisher={Cambridge University Press}, 
  author={Cesa-Bianchi, Nicolo and Lugosi, Gabor},
  year={2006}
}

@ARTICLE{reich2019influenza,
  title    = "A collaborative multiyear, multimodel assessment of seasonal
              influenza forecasting in the United States",
  author   = "Reich, Nicholas G and Brooks, Logan C and Fox, Spencer J and
              Kandula, Sasikiran and McGowan, Craig J and Moore, Evan and
              Osthus, Dave and Ray, Evan L and Tushar, Abhinav and Yamana,
              Teresa K and Biggerstaff, Matthew and Johansson, Michael A and
              Rosenfeld, Roni and Shaman, Jeffrey",
  abstract = "Influenza infects an estimated 9-35 million individuals each year
              in the United States and is a contributing cause for between
              12,000 and 56,000 deaths annually. Seasonal outbreaks of
              influenza are common in temperate regions of the world, with
              highest incidence typically occurring in colder and drier months
              of the year. Real-time forecasts of influenza transmission can
              inform public health response to outbreaks. We present the
              results of a multiinstitution collaborative effort to standardize
              the collection and evaluation of forecasting models for influenza
              in the United States for the 2010/2011 through 2016/2017
              influenza seasons. For these seven seasons, we assembled weekly
              real-time forecasts of seven targets of public health interest
              from 22 different models. We compared forecast accuracy of each
              model relative to a historical baseline seasonal average. Across
              all regions of the United States, over half of the models showed
              consistently better performance than the historical baseline when
              forecasting incidence of influenza-like illness 1 wk, 2 wk, and 3
              wk ahead of available data and when forecasting the timing and
              magnitude of the seasonal peak. In some regions, delays in data
              reporting were strongly and negatively associated with forecast
              accuracy. More timely reporting and an improved overall
              accessibility to novel and traditional data sources are needed to
              improve forecasting accuracy and its integration with real-time
              public health decision making.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  116,
  number   =  8,
  pages    = "3146--3154",
  month    =  feb,
  year     =  2019,
  keywords = "forecasting; infectious disease; influenza; public health;
              statistics",
  language = "en"
}

@article{friedman1983,
author = {Friedman, Jerome H. and Grosse, Eric and Stuetzle, Werner},
title = {Multidimensional Additive Spline Approximation},
journal = {SIAM Journal on Scientific and Statistical Computing},
volume = {4},
number = {2},
pages = {291-301},
year = {1983},
doi = {10.1137/0904023},
URL = {https://doi.org/10.1137/0904023},
eprint = {https://doi.org/10.1137/0904023},
abstract = { We describe an adaptive procedure that approximates a function of many variables by a sum of (univariate) spline functions \$s\_m \$ of selected linear combinations \$a\_m \cdot x\$ of the coordinates \[ \phi (x) = \sum\_{1 \leqq m \leqq M} {s\_m ( a\_m \cdot x)}. \] The procedure is nonlinear in that not only the spline coefficients but also the linear combinations are optimized for the particular problem. The sample need not lie on a regular grid, and the approximation is affine invariant, smooth, and lends itself to graphical interpretation. Function values, derivatives, and integrals are inexpensive to evaluate. }
}

@article{shafer2008conformal,
author = {Shafer, Glenn and Vovk, Vladimir},
title = {A Tutorial on Conformal Prediction},
year = {2008},
issue_date = {6/1/2008},
publisher = {JMLR.org},
volume = {9},
issn = {1532-4435},
abstract = {Conformal prediction uses past experience to determine precise levels of confidence in new predictions. Given an error probability ε, together with a method that makes a prediction undefined of a label y, it produces a set of labels, typically containing undefined, that also contains y with probability 1 – ε. Conformal prediction can be applied to any method for producing undefined: a nearest-neighbor method, a support-vector machine, ridge regression, etc.Conformal prediction is designed for an on-line setting in which labels are predicted successively, each one being revealed before the next is predicted. The most novel and valuable feature of conformal prediction is that if the successive examples are sampled independently from the same distribution, then the successive predictions will be right 1 – ε of the time, even though they are based on an accumulating data set rather than on independent data sets.In addition to the model under which successive examples are sampled independently, other on-line compression models can also use conformal prediction. The widely used Gaussian linear model is one of these.This tutorial presents a self-contained account of the theory of conformal prediction and works through several numerical examples. A more comprehensive treatment of the topic is provided in Algorithmic Learning in a Random World, by Vladimir Vovk, Alex Gammerman, and Glenn Shafer (Springer, 2005).},
journal = {J. Mach. Learn. Res.},
month = {jun},
pages = {371–421},
numpages = {51}
}

@misc{angelopoulos2022gentle,
      title={A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification}, 
      author={Anastasios N. Angelopoulos and Stephen Bates},
      year={2022},
      eprint={2107.07511},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{barber2023conformal,
      title={Conformal prediction beyond exchangeability}, 
      author={Rina Foygel Barber and Emmanuel J. Candes and Aaditya Ramdas and Ryan J. Tibshirani},
      year={2023},
      eprint={2202.13415},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}
@Article{wright2017ranger,
    title = {{ranger}: A Fast Implementation of Random Forests for High Dimensional Data in {C++} and {R}},
    author = {Marvin N. Wright and Andreas Ziegler},
    journal = {Journal of Statistical Software},
    year = {2017},
    volume = {77},
    number = {1},
    pages = {1--17},
    doi = {10.18637/jss.v077.i01},
  }

@Article{krammer2018influenza,
author={Krammer, Florian
and Smith, Gavin J. D.
and Fouchier, Ron A. M.
and Peiris, Malik
and Kedzierska, Katherine
and Doherty, Peter C.
and Palese, Peter
and Shaw, Megan L.
and Treanor, John
and Webster, Robert G.
and Garc{\'i}a-Sastre, Adolfo},
title={Influenza},
journal={Nature Reviews Disease Primers},
year={2018},
month={Jun},
day={28},
volume={4},
number={1},
pages={3},
abstract={Influenza is an infectious respiratory disease that, in humans, is caused by influenza A and influenza B viruses. Typically characterized by annual seasonal epidemics, sporadic pandemic outbreaks involve influenza A virus strains of zoonotic origin. The WHO estimates that annual epidemics of influenza result in {\textasciitilde}1 billion infections, 3--5 million cases of severe illness and 300,000--500,000 deaths. The severity of pandemic influenza depends on multiple factors, including the virulence of the pandemic virus strain and the level of pre-existing immunity. The most severe influenza pandemic, in 1918, resulted in{\thinspace}>40 million deaths worldwide. Influenza vaccines are formulated every year to match the circulating strains, as they evolve antigenically owing to antigenic drift. Nevertheless, vaccine efficacy is not optimal and is dramatically low in the case of an antigenic mismatch between the vaccine and the circulating virus strain. Antiviral agents that target the influenza virus enzyme neuraminidase have been developed for prophylaxis and therapy. However, the use of these antivirals is still limited. Emerging approaches to combat influenza include the development of universal influenza virus vaccines that provide protection against antigenically distant influenza viruses, but these vaccines need to be tested in clinical trials to ascertain their effectiveness.},
issn={2056-676X},
doi={10.1038/s41572-018-0002-y},
url={https://doi.org/10.1038/s41572-018-0002-y}
}

@article{lofgren2007influenza,
author = {Eric Lofgren and N. H. Fefferman and Y. N. Naumov and J. Gorski and E. N. Naumova},
title = {Influenza Seasonality: Underlying Causes and Modeling Theories},
journal = {Journal of Virology},
volume = {81},
number = {11},
pages = {5429-5436},
year = {2007},
doi = {10.1128/jvi.01680-06},

URL = {https://journals.asm.org/doi/abs/10.1128/jvi.01680-06},
eprint = {https://journals.asm.org/doi/pdf/10.1128/jvi.01680-06}

}

@Article{biggerstaff2016flusight,
author={Biggerstaff, Matthew
and Alper, David
and Dredze, Mark
and Fox, Spencer
and Fung, Isaac Chun-Hai
and Hickmann, Kyle S.
and Lewis, Bryan
and Rosenfeld, Roni
and Shaman, Jeffrey
and Tsou, Ming-Hsiang
and Velardi, Paola
and Vespignani, Alessandro
and Finelli, Lyn
and for the Influenza Forecasting Contest Working Group},
title={Results from the centers for disease control and prevention's predict the 2013--2014 Influenza Season Challenge},
journal={BMC Infectious Diseases},
year={2016},
month={Jul},
day={22},
volume={16},
number={1},
pages={357},
abstract={Early insights into the timing of the start, peak, and intensity of the influenza season could be useful in planning influenza prevention and control activities. To encourage development and innovation in influenza forecasting, the Centers for Disease Control and Prevention (CDC) organized a challenge to predict the 2013--14 Unites States influenza season.},
issn={1471-2334},
doi={10.1186/s12879-016-1669-x},
url={https://doi.org/10.1186/s12879-016-1669-x}
}

@misc{tushar2018flusightnetwork,
  author = {Tushar, Abhinav and Reich, Nicholas and Yamana, Teresa and Osthus, Dave and McGowan, Craig and Ray, Evan and et al.},
  title = {FluSightNetwork: cdc-flusight-ensemble repository},
  year = {2018},
  howpublished = {\url{https://github.com/FluSightNetwork/cdc-flusight-ensemble}}
}